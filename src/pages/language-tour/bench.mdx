import { Callout } from "nextra-theme-docs";

# Bench

Aiken has built-in support for benchmarking through a syntax similar to property-based tests. Benchmarks allow you to measure execution costs (memory and CPU) across increasing input complexity.

## Writing benchmarks 

To write a benchmark, use the `bench` keyword along with a `Sampler`. A sampler takes a complexity parameter and generates increasingly complex inputs based on a specified growth pattern:

```aiken
use aiken/bench

fn my_function(n: Int) -> Int {
  n * 2
}

bench multiply_bench(n via bench.int(bench.Linear(5))) {
  my_function(n)
}
```

A `Sampler` is introduced as a special annotation for the argument using the `via` keyword. The bench library uses a `Growth` pattern to control how input complexity scales:

- `Constant` - Fixed complexity
- `Linear(base)` - Linear growth: f(n) = base * n
- `Exponential(base)` - Exponential growth: f(n) = base^n  
- `Logarithmic(base)` - Logarithmic growth: f(n) = log_base(n)

## Composing samplers

Samplers can be composed to create more complex benchmarking scenarios:

```aiken
use aiken/bench

bench list_operation(xs via bench.list(bench.int(bench.Linear(1)), bench.Linear(5))) {
  list.reverse(xs)
}
```

## Benchmark reports

Benchmarks are executed using the `aiken bench` command. They provide a report showing execution costs (memory and CPU) across different complexity levels.
This allows you to analyze how your code's performance scales with input complexity.

## Built-in samplers

The `aiken/bench` module provides several built-in samplers for common types:

```aiken
use aiken/bench

// Integer sampler with linear growth
bench.int(bench.Linear(5))

// List sampler with configurable element sampler and length growth
bench.list(element_sampler, bench.Linear(3))

// ByteArray sampler with configurable length growth
bench.bytestring(bench.Linear(2))

// Dict sampler with configurable key/value samplers and size growth
bench.dict(key_sampler, value_sampler, bench.Linear(2))

// Combine samplers using map/map2
bench.map(sampler, fn(x) { ... })
bench.map2(sampler1, sampler2, fn(x, y) { ... })
```

## Running specific benchmarks

Like tests, you can run specific benchmarks using the same `aiken bench` flags:

```sh
# Run benchmarks in specific module
aiken bench -m "my_module"

# Run specific benchmark
aiken bench -e -m "my_bench"
```

<Callout type="info">
Benchmarks are particularly useful when optimizing validator scripts since they allow you to measure execution costs across different input sizes and complexity levels.
</Callout>

For more information about the testing functionality that benchmarking builds upon, see the [testing documentation](/language-tour/tests).
